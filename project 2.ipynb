{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b356f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c29505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37884cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchvision\n",
    "\n",
    "#!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e177cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "\n",
    "plt.ion() #interactive mode\n",
    "\n",
    "from torchvision.models import ResNet50_Weights, ResNet18_Weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f58270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir()\n",
    "\n",
    "#training_data='./Data/Throughput/A_folderize/train'\n",
    "input_path = './Data/Input/'\n",
    "\n",
    "\n",
    "input_train = input_path + 'train_set/train_set/'\n",
    "input_test = input_path + 'test_set/test_set/test_set/'\n",
    "input_labels_test = input_path + 'sample.csv'\n",
    "input_labels_train = input_path + 'train_labels.csv'\n",
    "    \n",
    "throughput_path = './Data/Throughput/'\n",
    "A_trainset = throughput_path + 'A_folderize/train/'\n",
    "A_testset = throughput_path + 'A_folderize/test/'\n",
    "A_validationset = os.path.join(throughput_path, 'A_folderize/train')\n",
    "save_model='./save_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938ff27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # a_folderize\n",
    "# def make_folders():\n",
    "#     for path in [A_trainset, A_testset]: #create directories\n",
    "#         if not os.path.exists(path):\n",
    "#             os.mkdir(path)\n",
    "# def copy_file(source, destination):\n",
    "#     shutil.copyfile(source, destination)\n",
    "    \n",
    "# def A_Folderize(force = True):\n",
    "    \n",
    "#     \"\"\"Creates folders that are necessary in general and for training data.\n",
    "\n",
    "#     This function creates folders that are necessary in general and for training\n",
    "#     data, and then puts pictures in the newly created folders. The `force`\n",
    "#     parameter is optional and is set to `False` by default. If set to `True`,\n",
    "#     the function will re-create the folders even if they already exist.\n",
    "\n",
    "#     Args:\n",
    "#         force: bool, optional\n",
    "#             If set to `True`, the function will re-create the folders even if\n",
    "#             they already exist.\n",
    "\n",
    "#     Returns:\n",
    "#         None\n",
    "#     \"\"\"\n",
    "#     print('START: A_folderize')\n",
    "#     print('Creating folders that are necessary in general')\n",
    "#     make_folders()\n",
    "\n",
    "#     labels_test = pd.read_csv(input_labels_test)\n",
    "#     labels_train = pd.read_csv(input_labels_train)\n",
    "\n",
    "#     print('Creating folders that are necessary for training data')\n",
    "#     pathh = os.path.join(A_trainset, '0')\n",
    "#     if (not os.path.exists(pathh)) | force:\n",
    "#         for label in labels_train['label'].unique():\n",
    "#             path = os.path.join(A_trainset, str(label - 1))\n",
    "#             os.mkdir(path)\n",
    "#         for label in labels_test['label'].unique():\n",
    "#             path = os.path.join(A_testset, str(label - 1))\n",
    "#             os.mkdir(path)\n",
    "\n",
    "#         print('Putting pictures in the newly created folders')\n",
    "#         for picpath in os.listdir(input_train): #picpath is the pathway to one image and the image its img_name,\n",
    "#             labelfolder = labels_train.loc[labels_train['img_name'] == picpath]['label'].iloc[0] #this returns a number indicating a foodclass\n",
    "#             copy_file(os.path.join(input_train, picpath),\n",
    "#                          os.path.join(A_trainset, str(labelfolder - 1), picpath))\n",
    "#         for picpath in os.listdir(input_test):\n",
    "#             labelfolder = labels_test.loc[labels_test['img_name'] == picpath]['label'].iloc[0]\n",
    "#             copy_file(os.path.join(input_test, picpath),\n",
    "#                          os.path.join(A_testset, str(labelfolder - 1), picpath))\n",
    "\n",
    "#     print('DONE: A_folderize')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a02daf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8badc49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d9de9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d1984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e939ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mean and std values for normalization\n",
    "means = [0.6366, 0.5437, 0.4454]\n",
    "stds = [0.2235, 0.2422, 0.2654]\n",
    "def C_PrepareData(input_size):\n",
    "    \"\"\"Prepares data for training, validation, and testing.\n",
    "    This function prepares data for training, validation, and testing by\n",
    "    applying transformations to the images in the datasets and loading the\n",
    "    transformed images into data loaders.\n",
    "    Args:\n",
    "        input_size: int\n",
    "            The input size of the model.\n",
    "    Returns:\n",
    "        train_loader: the data loader for the training dataset\n",
    "        val_loader: the data loader for the validation dataset\n",
    "        test_loader: the data loader for the testing dataset\n",
    "    \"\"\"\n",
    "\n",
    "    print('START: C_PrepareData')\n",
    "    # resize, pixels. resize depending on data, we have to explore other sizes to check for performance\n",
    "    training_transforms = transforms.Compose([transforms.Resize((input_size, input_size)), transforms.ToTensor()])\n",
    "    print(training_transforms)\n",
    "\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root=A_trainset, transform=training_transforms)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # image data preparation\n",
    "    # normalized data=> image=(image-mean)/std\n",
    "    # Data augmentation and normalization for training\n",
    "    # Just normalization for validation\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size), # TODO: Check if better crop or transforms.Resize((input_size, input_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means,stds)\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size), # TODO: Check if resizing helps or not\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    data_transforms['test'] = data_transforms['val']\n",
    "\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root=A_trainset, transform=data_transforms['train'])\n",
    "    val_dataset = torchvision.datasets.ImageFolder(root=A_validationset, transform=data_transforms['val'])\n",
    "    test_dataset = torchvision.datasets.ImageFolder(root=A_testset, transform=data_transforms['test'])\n",
    "\n",
    "    # Mini-Batch Gradient Descent, start with 32 and explore to increase performance\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "    print('DONE: C_PrepareData')\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f5e091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C_PrepareData(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "859faeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "\n",
    "# Set number of training epochs and batch size\n",
    "num_epochs = 15\n",
    "batch_size = 16\n",
    "\n",
    "# Set learning rate and momentum\n",
    "learning_rate = 0.009\n",
    "momentum = 0.11\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "# when True we only update the reshaped layer params\n",
    "feature_extract = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5b4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5581d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(model):\n",
    "    \"\"\"Modify the fully-connected layer of a PyTorch model to match the number of features and classes in the input data.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The PyTorch model to modify.\n",
    "    Returns:\n",
    "        torch.nn.Module: The modified PyTorch model.\n",
    "    \"\"\"\n",
    "    num_fts = model.fc.in_features\n",
    "    number_of_classes = len(pd.read_csv(paths.input_labels_train)['label'].unique())\n",
    "\n",
    "    model.fc = nn.Linear(num_fts, number_of_classes)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "def init_optimizer(model_ft, device, feature_extract = True):\n",
    "    # Send the model to GPU\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    # Gather the parameters to be optimized/updated in this run. If we are\n",
    "    #  finetuning we will be updating all parameters. However, if we are\n",
    "    #  doing feature extract method, we will only update the parameters\n",
    "    #  that we have just initialized, i.e. the parameters with requires_grad\n",
    "    #  is True.\n",
    "    params_to_update = model_ft.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\", name)\n",
    "    else:\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\", name)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(params_to_update, lr=0.01, momentum=0.11)\n",
    "    return optimizer_ft\n",
    "\n",
    "\n",
    "def train_nn(model, optimizer, train_loader, test_loader, criterion,\n",
    "             n_epochs):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        total = 0\n",
    "#validation\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels == predicted).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = running_correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Correct: {running_correct} ({epoch_acc}%); Loss: {epoch_loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "480d4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=num_epochs, is_inception=False):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    # Print the model we just instantiated\n",
    "    print(f\"Model: {model}\")\n",
    "\n",
    "    # Send the model to GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Gather the parameters to be optimized/updated in this run. If we are\n",
    "    #  finetuning we will be updating all parameters. However, if we are\n",
    "    #  doing feature extract method, we will only update the parameters\n",
    "    #  that we have just initialized, i.e. the parameters with requires_grad\n",
    "    #  is True.\n",
    "    params_to_update = model.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer = optim.SGD(params_to_update, lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    # Setup the loss fxn\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            dataloaders = {\n",
    "                'train': train_loader,\n",
    "                'val': val_loader\n",
    "            }\n",
    "            for data in dataloaders[phase]:\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d92aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet18\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"resnet50\":\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        Exception(\"Invalid model name, exiting. To change model name, change the model_name variable in Config.ConfigMain\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "model_name = \"resnet50\"\n",
    "feature_extract=True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def B_InitModel():\n",
    "    \"\"\"Initializes a model.\n",
    "    This function initializes a model and returns the initialized model and its\n",
    "    input size.\n",
    "    Returns:\n",
    "        model: the initialized model\n",
    "        input_size: the input size of the model\n",
    "    \"\"\"\n",
    "    print('START: B_InitModel')\n",
    "    num_classes = len(os.listdir(A_trainset))\n",
    "    model, input_size = initialize_model(model_name, num_classes, feature_extract)\n",
    "    print('DONE: B_InitModel')\n",
    "    return model, input_size\n",
    "#B_InitModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9264cac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "657f2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_TrainModel(model, train_loader, test_loader):\n",
    "    print('START: D_TrainModel')\n",
    "    model = train_model(model, train_loader, test_loader, num_epochs=num_epochs, is_inception=False)\n",
    "    print('DONE: D_TrainModel')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7900dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def predict(model, test_loader): \n",
    "#     predictions = []\n",
    "#     model.eval() #set to evaluate, which might impact how the calculations are done\n",
    "#     with torch.no_grad(): #no gradient needs to be computed for evaluation\n",
    "#         for x, y in test_loader:\n",
    "#             x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "#             score = model(x)\n",
    "#             predictions.append(score)\n",
    "\n",
    "#     \"\"\" \n",
    "#   predictions = []\n",
    "#   for item in test_loader:\n",
    "#     print (item)\n",
    "#     with torch.no_grad():\n",
    "#         # Iterate over data.\n",
    "#         for inputs, _ in test_loader:\n",
    "#             outputs = model(inputs)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#         predictions.extend(preds.numpy())\n",
    "#     \"\"\"\n",
    "#     return predictions\n",
    "\n",
    "def E_PredictModel(model, test_loader):\n",
    "    print(\"Predictions\")\n",
    "    model.eval()\n",
    "    #with torch.no_grad():\n",
    "    imagenames = []\n",
    "\n",
    "    for data in test_loader.dataset.imgs:\n",
    "        imgname = data[0].split(\"/\")[-1]\n",
    "        imgname = imgname[2:]\n",
    "        imagenames.append(imgname)\n",
    "        break\n",
    "    \n",
    "    \n",
    "\n",
    "    predictions = []\n",
    "    for item_image, _ in test_loader.dataset:\n",
    "        current_image = torch.unsqueeze(item_image, 0)\n",
    "        perhaps_image_name, prediction_class = torch.max(model(current_image), 1)\n",
    "        this_prediction = prediction_class[0]\n",
    "        print(perhaps_image_name, int(this_prediction))\n",
    "        predictions.append(int(this_prediction))\n",
    "        break\n",
    "    print(predictions)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"img_name\" : imagenames,\n",
    "        \"label\" : predictions\n",
    "    })\n",
    "    print(df)\n",
    "    df.to_csv(\"test_van_resnet.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e16ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.13.0+cpu\n",
      "Torchvision Version:  0.14.0+cpu\n",
      "START: B_InitModel\n",
      "DONE: B_InitModel\n",
      "START: C_PrepareData\n",
      "Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
      "    ToTensor()\n",
      ")\n",
      "DONE: C_PrepareData\n",
      "START: D_TrainModel\n",
      "Model: ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=80, bias=True)\n",
      ")\n",
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "Epoch 0/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 4.1602 Acc: 0.1324\n",
      "val Loss: 3.8872 Acc: 0.2477\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 3.7876 Acc: 0.2374\n",
      "val Loss: 3.5169 Acc: 0.3083\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 3.5153 Acc: 0.2773\n",
      "val Loss: 3.2220 Acc: 0.3501\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 3.3128 Acc: 0.3108\n",
      "val Loss: 3.0176 Acc: 0.3818\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 3.1592 Acc: 0.3279\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "def main(*pipeparts):\n",
    "    if 'A' in pipeparts:\n",
    "        A_Folderize(force=False)\n",
    "    if 'B' in pipeparts:\n",
    "        model, input_size = B_InitModel()\n",
    "    if 'C' in pipeparts:\n",
    "        train_loader, val_loader, test_loader = C_PrepareData(input_size)\n",
    "    if 'D' in pipeparts:\n",
    "        model = D_TrainModel(model, train_loader, val_loader)\n",
    "        # Save the model's state_dict\n",
    "        torch.save(model.state_dict(), save_model)\n",
    "        print('Saved Pytorch model state')\n",
    "        model.load_state_dict(torch.load(save_model))\n",
    "    if 'E' in pipeparts:\n",
    "        predictions = pipe.E_PredictModel(model, test_loader)\n",
    "\n",
    "    return predictions\n",
    "    \n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define which parts of the pipeline to execute (include 'A' in first execution, then 'A' does not need to be run)\n",
    "    pipeparts = ['B', 'C', 'D','E']\n",
    "    main(*pipeparts)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207384f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start:around 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0594652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9eebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def D_EvaluateModel():\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for images, labels in test_loader:\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "#         del images, labels, outputs\n",
    "\n",
    "#     print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))   \n",
    "    \n",
    "#     #same as validation but with test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60431310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09fa21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a7fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model():\n",
    "    # TODO: Not finished yet\n",
    "    # Plot the training curves of validation accuracy vs. number\n",
    "    #  of training epochs for the transfer learning method and\n",
    "    #  the model trained from scratch\n",
    "    hist = []\n",
    "    ohist = [h.cpu().numpy() for h in hist]\n",
    "    plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "    plt.xlabel(\"Training Epochs\")\n",
    "    plt.ylabel(\"Validation Accuracy\")\n",
    "    plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "    plt.ylim((0,1.))\n",
    "    plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a133ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560794e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c56b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40692b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_mean_and_std(loader):\n",
    "#     mean=0.\n",
    "#     std=0.\n",
    "#     total_images_count=0\n",
    "#     for images,_ in loader:\n",
    "#         image_count_in_a_batch=images.size(0)\n",
    "#         images=images.view(image_count_in_a_batch, images.size(1), -1)\n",
    "#         mean+=images.mean(2).sum(0)\n",
    "#         std+=images.std(2).sum(0)\n",
    "#         total_images_count+=image_count_in_a_batch\n",
    "#     mean/=total_images_count\n",
    "#     std/=total_images_count\n",
    "#     return mean,std\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b94e73",
   "metadata": {},
   "outputs": [],
   "source": [
    " #get_mean_and_std(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10adf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da405b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4eeea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c8d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862950f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27edd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_transf_images(data):\n",
    "#     loader=torch.utils.data.DataLoader(data,batch_size=6, shuffle=True)\n",
    "#     batch=next(iter(loader))\n",
    "#     images,labels=batch\n",
    "    \n",
    "#     grid=torchvision.utils.make_grid(images,nrow=3)\n",
    "#     plt.figure(figsize=(11,11))\n",
    "#     plt.imshow(np.transpose(grid,(1,2,0)))\n",
    "#     print('labels:',labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_transf_images(test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2951a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56378cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530afcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcddfa35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a7916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e23009b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc3a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496c1637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
